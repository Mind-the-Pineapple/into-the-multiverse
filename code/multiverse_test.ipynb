{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiverse_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHW7cYvz0a74",
        "colab_type": "text"
      },
      "source": [
        "# Setting up the enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzOXabS-wOg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cloning the git repo with the data structure\n",
        "!git clone https://github.com/JessyD/test.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtCBYS1Q07ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install necessary python dependencies\n",
        "! pip install -r test/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1tU-46g1f72",
        "colab_type": "text"
      },
      "source": [
        "# Download the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOQ5bQxoL-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O test/data/nspn.fmri.main.RData https://ndownloader.figshare.com/files/20958708"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16eWfSDM1uSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O test/data/nspn.fmri.gsr.RData https://ndownloader.figshare.com/files/20958699"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC9v-PY82lun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O test/data/nspn.fmri.lowmot.RData https://ndownloader.figshare.com/files/20958702"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPaw6pyIhy4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O test/data/nspn.fmri.general.vars.RData https://ndownloader.figshare.com/files/20819796"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBm5C8HB3Okj",
        "colab_type": "text"
      },
      "source": [
        "# Define key variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra4NkHs2gjlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import random\n",
        "\n",
        "import pyreadr \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colorbar\n",
        "import bct\n",
        "from scipy import stats\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "from helperfunctions import gateway_coef_sign\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQR-qpAVhTz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the random seed\n",
        "#np.random.seed(2)\n",
        "rng = np.random.default_rng(2)\n",
        "random.seed(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mapfQZqEixXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define paths\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "data_path = PROJECT_ROOT / 'test' /'data'\n",
        "output_path = PROJECT_ROOT / 'test' / 'output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he7t6Vu6omM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1 = pyreadr.read_r(str(data_path / 'nspn.fmri.main.RData'))\n",
        "data3 = pyreadr.read_r(str(data_path / 'nspn.fmri.lowmot.RData'))\n",
        "genVar = pyreadr.read_r(str(data_path / 'nspn.fmri.general.vars.RData'))\n",
        "data2 = pyreadr.read_r(str(data_path / 'nspn.fmri.gsr.RData'))\n",
        "\n",
        "DataNames=['nspn.fmri.main.RData','nspn.fmri.gsr.RData','nspn.fmri.lowmot.RData']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Gv0TyC25o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some images properites\n",
        "n_regions = 346\n",
        "subject_array = 520\n",
        "\n",
        "#Get motion regression functional connectivity data and reshape into \n",
        "# region x region x subject array\n",
        "FC = np.asarray(data1['fc.main'])\n",
        "MainNoNan = np.nan_to_num(FC,copy=True,nan=1.0)\n",
        "MainNoNanReshape = np.reshape(MainNoNan, [n_regions,n_regions,subject_array],\n",
        "                            order='F')\n",
        "\n",
        "#Get global signal regression functional connectivity data and reshape into\n",
        "# region x region x subject array\n",
        "FC=np.asarray(data2['fc.gsr'])\n",
        "GSRNoNan = np.nan_to_num(FC,copy=True,nan=1.0)\n",
        "GSRNoNanReshape = np.reshape(GSRNoNan, [n_regions,n_regions,subject_array],\n",
        "                           order='F')\n",
        "\n",
        "#Read in subject IDs and age\n",
        "IDMain=np.asarray(data1['id.main'])\n",
        "ages=np.asarray(data1['age.main'])\n",
        "\n",
        "#Find unique subject IDs and index of first instance and find FC data \n",
        "# corresponding to these indices\n",
        "IDs,IDIndexUnique = np.unique(IDMain,return_index=True)\n",
        "MainNoNanReshapeUnique = MainNoNanReshape[:,:,IDIndexUnique]\n",
        "GSRNoNanReshapeUnique = GSRNoNanReshape[:,:,IDIndexUnique]\n",
        "AgesUnique = ages[IDIndexUnique]\n",
        "\n",
        "# Number of randomly selected subjects to be used to define the low-dimensional \n",
        "# space then split FC data and age data into two: 50 for defining space and \n",
        "#remaining 248 for subsequent prediction\n",
        "SpaceDefineN = 50\n",
        "RandomIndexes = rng.choice(IDs.shape[0], size=IDs.shape[0], replace=False)\n",
        "MainNoNanModelSpace = MainNoNanReshapeUnique[:,:,RandomIndexes[0:SpaceDefineN]]\n",
        "MainNoNanPrediction = MainNoNanReshapeUnique[:,:,RandomIndexes[SpaceDefineN:]]\n",
        "GSRNoNanModelSpace = GSRNoNanReshapeUnique[:,:,RandomIndexes[0:SpaceDefineN]]\n",
        "GSRNoNanPrediction = GSRNoNanReshapeUnique[:,:,RandomIndexes[SpaceDefineN:]]\n",
        "AgesModelSpace = AgesUnique[RandomIndexes[0:SpaceDefineN]]\n",
        "AgesPrediction = AgesUnique[RandomIndexes[SpaceDefineN:]]\n",
        "IDsModelSpace = IDs[RandomIndexes[0:SpaceDefineN]] \n",
        "IDsPrediction = IDs[RandomIndexes[SpaceDefineN:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DAI4LaEsydR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get info about brain regions and find Yeo network IDs; useful later on for \n",
        "# graph metrics that need community labels.\n",
        "KeptIDs = np.asarray(genVar['hcp.keep.id'])\n",
        "YeoIDs = np.asarray(genVar['yeo.id.subc'])\n",
        "KeptYeoIDs = YeoIDs[KeptIDs-1][:,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79k8wv4MhhnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dictionary of 16 graph theory measures taken from the Brain Connectivity Toolbox\n",
        "\n",
        "BCT_models = {\n",
        "    'degree': bct.degrees_und,\n",
        "    'strength': bct.strengths_und,\n",
        "    'betweennness centrality': bct.betweenness_bin,\n",
        "    'clustering (bin.)': bct.clustering_coef_bu,\n",
        "    'clustering (wei.)': bct.clustering_coef_wu,\n",
        "    'eigenvector centrality': bct.eigenvector_centrality_und,\n",
        "    'sugraph centrality': bct.subgraph_centrality,\n",
        "    'local efficiency' : bct.efficiency_bin,\n",
        "    'modularity (louvain)': bct.modularity_louvain_und,\n",
        "    'modularity (probtune)': bct.modularity_probtune_und_sign,\n",
        "    'participation coefficient': bct.participation_coef,\n",
        "    'module degree z-score': bct.module_degree_zscore,\n",
        "    'pagerank centrality': bct.pagerank_centrality,\n",
        "    'diversity coefficient': bct.diversity_coef_sign,\n",
        "    'gateway degree': gateway_coef_sign,\n",
        "    'k-core centrality': bct.kcoreness_centrality_bu,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5mCueTin-12",
        "colab_type": "text"
      },
      "source": [
        "## Generating data to build low-dimensional space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puxCTglyiKVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This involves exhaustive evaluation of all 544 analysis approaches.  \n",
        "\n",
        "BCT_Run = {}\n",
        "Sparsities_Run= {}\n",
        "Data_Run = {}\n",
        "GroupSummary = {}\n",
        "\n",
        "thresholds = [0.4,0.3,0.25,0.2,0.175,0.150,0.125,0.1,0.09,0.08,\n",
        "              0.07,0.06,0.05,0.04,0.03,0.02,0.01]\n",
        "preprocessing = ['MRS', 'GRS']\n",
        "\n",
        "n_thr = len(thresholds)\n",
        "n_pre = len(preprocessing)\n",
        "n_BCT = len(BCT_models.keys())\n",
        "Results = np.zeros(((n_thr * n_pre * n_BCT), n_regions))\n",
        "ResultsIndVar = np.zeros(((n_thr * n_pre * n_BCT), 1225))\n",
        "count=0\n",
        "for count in tqdm(range(n_thr * n_pre * n_BCT)):\n",
        "  for DataPreproc in preprocessing: # data preprocessing\n",
        "    if DataPreproc == 'MRS':\n",
        "        TempData = MainNoNanModelSpace\n",
        "        TotalSubjects = TempData.shape[2]\n",
        "    elif DataPreproc == 'GRS':\n",
        "        TempData = GSRNoNanModelSpace\n",
        "        TotalSubjects = TempData.shape[2]\n",
        "\n",
        "    for thr_idx, TempThreshold in enumerate(thresholds): # FC threshold level\n",
        "        for BCT_Num in BCT_models.keys(): # Graph theory measure\n",
        "            TempResults = np.zeros((TotalSubjects,n_regions))\n",
        "            for SubNum in range(TotalSubjects):\n",
        "                ss = analysis_space(BCT_Num, BCT_models, x, KeptYeoIDs)\n",
        "                #For each subject for each approach keep the 346 regional values.        \n",
        "                TempResults[SubNum, :] = ss \n",
        "\n",
        "            BCT_Run[count] = BCT_Num;\n",
        "            Sparsities_Run[count] = TempThreshold\n",
        "            Data_Run[count] = DataPreproc\n",
        "            GroupSummary[count] ='Mean'\n",
        "            # Build an array of similarities between subjects for each\n",
        "            # analysis approach \n",
        "            cos_sim = cosine_similarity(TempResults, TempResults)        \n",
        "            Results[count, :] = np.mean(TempResults, axis=0)\n",
        "            ResultsIndVar[count, :] = cos_sim[np.triu_indices(TotalSubjects, k=1)].T                         \n",
        "                     \n",
        "ModelsResults={\"Results\": Results,\n",
        "               \"ResultsIndVar\": ResultsIndVar,\n",
        "               \"BCT\": BCT_Run,\n",
        "               \"Sparsities\": Sparsities_Run, \n",
        "               \"Data\": Data_Run, \n",
        "               \"SummaryStat\": GroupSummary,\n",
        "               \"Ages\": np.array(data1['age.main']),\n",
        "               \"AgesPrediction\": AgesPrediction,\n",
        "               \"MainNoNanPrediction\": MainNoNanPrediction,\n",
        "               \"GSRNoNanPrediction\": GSRNoNanPrediction,\n",
        "               \"keptYeoIDs\": KeptYeoIDs}\n",
        "            \n",
        "pickle.dump( ModelsResults, open(str(output_path / \"ModelsResults.p\"), \"wb\" ) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxVWimqHnyM0",
        "colab_type": "text"
      },
      "source": [
        "## Building the low-dimensional space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUYIJG675JWn",
        "colab_type": "text"
      },
      "source": [
        "### LLE, SE, tSNE Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ArZnzq35WAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import manifold, datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import OrderedDict\n",
        "from functools import partial\n",
        "from time import time\n",
        "import pickle\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import NullFormatter\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "import matplotlib.pyplot as plt\n",
        "from umap.umap_ import UMAP\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnseTiW87I53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the previous results\n",
        "ModelResults = pickle.load(open(str(output_path / \"ModelsResults.p\"), \"rb\" ) )\n",
        "Results = ModelResults['ResultsIndVar']\n",
        "BCT_Run = ModelResults['BCT']\n",
        "Sparsities_Run = ModelResults['Sparsities']\n",
        "Data_Run = ModelResults['Data']\n",
        "GroupSummary = ModelResults['SummaryStat']\n",
        "AgesPrediction = ModelResults['Ages'])\n",
        "preprocessing = ['MRS', 'GRS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6sfdK1TiiVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Scale the data prior to dimensionality reduction\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(Results.T)\n",
        "X = X.T\n",
        "n_neighbors = 20\n",
        "n_components = 2 #number of components requested. In this case for a 2D space.\n",
        "\n",
        "#Define different dimensionality reduction techniques \n",
        "methods = OrderedDict()\n",
        "LLE = partial(manifold.LocallyLinearEmbedding,\n",
        "              n_neighbors, n_components, eigen_solver='dense')\n",
        "methods['LLE'] = LLE(method='standard', random_state=0)\n",
        "methods['SE'] = manifold.SpectralEmbedding(n_components=n_components,\n",
        "                                           n_neighbors=n_neighbors, random_state=0)\n",
        "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',\n",
        "                                 random_state=0)\n",
        "methods['UMAP'] = UMAP(random_state=40, n_components=2, n_neighbors=200,\n",
        "                             min_dist=.8)\n",
        "methods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=10, \n",
        "                              random_state=21, metric=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPvvEjch7Qju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "markers = [\"x\",\"s\",\"o\",\"*\",\"D\",\"1\",\"v\",\"p\",\"H\",\"+\",\"|\",\"_\",\"3\",\"^\",\"4\",\"<\",\"X\"]\n",
        "colourmaps = {\"MRS\":\"Oranges\",\"GRS\":\"Purples\"}\n",
        "BCT = np.array(list(BCT_Run.items()))[:,1]\n",
        "Sparsities = np.array(list(Sparsities_Run.items()))[:,1]\n",
        "Data=np.array(list(Data_Run.items()))[:,1]\n",
        "\n",
        "# Reduced dimensions\n",
        "data_reduced = {}\n",
        "\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "fig.subplots_adjust(right=0.7)\n",
        "figDE = plt.figure(constrained_layout=False, figsize=(21,6))\n",
        "gsDE = figDE.add_gridspec(nrows=6, ncols=21)#, left=0.05, right=0.48, wspace=0.05)\n",
        "\n",
        "#Perform embedding and plot the results (including info about the approach in the color/intensity and shape).\n",
        "\n",
        "for i, (label, method) in enumerate(methods.items()):\n",
        "     \n",
        "    t0 = time()\n",
        "    Y = method.fit_transform(X)\n",
        "\n",
        "    t1 = time()\n",
        "    # Save the results\n",
        "    data_reduced[label] = Y\n",
        "    \n",
        "    ax = figDE.add_subplot(gsDE[:,i*6+i:(i+1)*6+i])\n",
        "    for d in preprocessing:\n",
        "\n",
        "        BCTTemp=BCT[Data==d]\n",
        "        SparsitiesTemp=Sparsities[Data==d]\n",
        "        YTemp=Y[Data==d,:]\n",
        "\n",
        "        \n",
        "        for i, c in enumerate(np.unique(BCTTemp)):\n",
        "            im=ax.scatter(YTemp[:,0][BCTTemp==c],YTemp[:,1][BCTTemp==c],\n",
        "                          c=SparsitiesTemp[BCTTemp==c]*-0.6, marker=markers[i],\n",
        "                          cmap=colourmaps[d], s=80)\n",
        "\n",
        "    ax.set_title(\"%s \" % (label),fontsize=15,fontweight=\"bold\")\n",
        "\n",
        "    ax.axis('tight')\n",
        "\n",
        "OrangePatch = mpatches.Patch(color='orange', label='Motion Regression')\n",
        "PurplePatch = mpatches.Patch(color='purple', label='Global Signal Regression')\n",
        "\n",
        "\n",
        "Lines={}\n",
        "for i, bct_model in enumerate(BCT_models):\n",
        "    Lines[i] = mlines.Line2D([], [], color='black', linestyle='None',\n",
        "                             marker=markers[i], markersize=10, \n",
        "                             label=bct_model)\n",
        "\n",
        "\n",
        "figDE.savefig(str(output_path / 'DifferentEmbeddings.png'),dpi=300)\n",
        "figDE.savefig(str(output_path / 'DifferentEmbeddings.svg'),format=\"svg\")\n",
        "figDE.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIKa1oFHDRR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try UMAP\n",
        "Y = methods['UMAP'].fit_transform(X)\n",
        "data_reduced['UMAP'] = Y\n",
        "\n",
        "figUMAP = plt.figure(constrained_layout=False, figsize=(21,15))\n",
        "gsUMAP = figUMAP.add_gridspec(nrows=15, ncols=20)\n",
        "ax = figUMAP.add_subplot(gsUMAP[:,0:15])\n",
        "\n",
        "for d in preprocessing:\n",
        "    BCTTemp=BCT[Data==d]\n",
        "    SparsitiesTemp=Sparsities[Data==d]\n",
        "    YTemp=Y[Data==d,:]\n",
        "\n",
        "    for i, c in enumerate(BCT_models):\n",
        "        im=ax.scatter(YTemp[:,0][BCTTemp==c],YTemp[:,1][BCTTemp==c],\n",
        "                      c=SparsitiesTemp[BCTTemp==c]*0.1, marker=markers[i],\n",
        "                      cmap=colourmaps[d], s=150)\n",
        "        ax.spines['top'].set_linewidth(1.5)\n",
        "        ax.spines['right'].set_linewidth(1.5)\n",
        "        ax.spines['bottom'].set_linewidth(1.5)\n",
        "        ax.spines['left'].set_linewidth(1.5)\n",
        "        ax.set_xlabel('Dimension 2',fontsize=20,fontweight=\"bold\")\n",
        "        ax.set_ylabel('Dimension 1',fontsize=20,fontweight=\"bold\")\n",
        "        ax.tick_params(labelsize=15)\n",
        "\n",
        "\n",
        "ax.set_title('UMAP', fontsize=25,fontweight=\"bold\")\n",
        "\n",
        "\n",
        "OrangePatch = mpatches.Patch(color='orange', label='motion regression')\n",
        "PurplePatch = mpatches.Patch(color=[85/255, 3/255, 152/255], label='global signal regression')\n",
        "\n",
        "IntensityPatch1 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.4', alpha=1)\n",
        "IntensityPatch2 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.1', alpha=0.4)\n",
        "IntensityPatch3 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.01', alpha=0.1)\n",
        "\n",
        "BlankLine=mlines.Line2D([], [], linestyle='None')\n",
        "\n",
        "Lines={}\n",
        "for i, bct_model in enumerate(BCT_models):\n",
        "    Lines[i] = mlines.Line2D([], [], color='black', linestyle='None',\n",
        "                             marker=markers[i],markersize=10, \n",
        "                             label=bct_model)\n",
        "\n",
        "figUMAP.legend(handles=[OrangePatch, PurplePatch,BlankLine,IntensityPatch1,\n",
        "                       IntensityPatch2, IntensityPatch3,BlankLine,\n",
        "                       Lines[0],Lines[1],Lines[2],Lines[3],Lines[4],Lines[5],\n",
        "                       Lines[6],Lines[7],Lines[8],Lines[9],Lines[10],Lines[11],\n",
        "                       Lines[12],Lines[13],Lines[14],Lines[15]],fontsize=15,\n",
        "              frameon=False,bbox_to_anchor=(1.4, 0.8),bbox_transform=ax.transAxes)\n",
        "\n",
        " \n",
        "figUMAP.savefig(str(output_path / 'UMAPSpace.png'), dpi=300)\n",
        "figUMAP.savefig(str(output_path /'UMAPpace.svg'), format=\"svg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggt7wfAfkAiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Do the same as above but for MDS\n",
        "Y = methods['MDS'].fit_transform(X)\n",
        "data_reduced['MDS'] = Y\n",
        "\n",
        "figMDS = plt.figure(constrained_layout=False, figsize=(21,15))\n",
        "gsMDS = figMDS.add_gridspec(nrows=15, ncols=20)\n",
        "ax = figMDS.add_subplot(gsMDS[:,0:15])\n",
        "\n",
        "for d in preprocessing:\n",
        "    BCTTemp=BCT[Data==d]\n",
        "    SparsitiesTemp=Sparsities[Data==d]\n",
        "    YTemp=Y[Data==d,:]\n",
        "\n",
        "    for i, c in enumerate(BCT_models):\n",
        "        im=ax.scatter(YTemp[:,0][BCTTemp==c],YTemp[:,1][BCTTemp==c],\n",
        "                      c=SparsitiesTemp[BCTTemp==c]*0.1, marker=markers[i],\n",
        "                      cmap=colourmaps[d], s=150)\n",
        "        ax.spines['top'].set_linewidth(1.5)\n",
        "        ax.spines['right'].set_linewidth(1.5)\n",
        "        ax.spines['bottom'].set_linewidth(1.5)\n",
        "        ax.spines['left'].set_linewidth(1.5)\n",
        "        ax.set_xlabel('Dimension 2',fontsize=20,fontweight=\"bold\")\n",
        "        ax.set_ylabel('Dimension 1',fontsize=20,fontweight=\"bold\")\n",
        "        ax.tick_params(labelsize=15)\n",
        "\n",
        "\n",
        "ax.set_title('Multi-dimensional Scaling', fontsize=25,fontweight=\"bold\")\n",
        "\n",
        "\n",
        "OrangePatch = mpatches.Patch(color='orange', label='motion regression')\n",
        "PurplePatch = mpatches.Patch(color=[85/255, 3/255, 152/255], label='global signal regression')\n",
        "\n",
        "IntensityPatch1 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.4', alpha=1)\n",
        "IntensityPatch2 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.1', alpha=0.4)\n",
        "IntensityPatch3 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='threshold: 0.01', alpha=0.1)\n",
        "\n",
        "BlankLine=mlines.Line2D([], [], linestyle='None')\n",
        "\n",
        "Lines={}\n",
        "for i, bct_model in enumerate(BCT_models):\n",
        "    Lines[i] = mlines.Line2D([], [], color='black', linestyle='None',\n",
        "                             marker=markers[i],markersize=10, \n",
        "                             label=bct_model)\n",
        "\n",
        "figMDS.legend(handles=[OrangePatch, PurplePatch,BlankLine,IntensityPatch1,\n",
        "                       IntensityPatch2, IntensityPatch3,BlankLine,\n",
        "                       Lines[0],Lines[1],Lines[2],Lines[3],Lines[4],Lines[5],\n",
        "                       Lines[6],Lines[7],Lines[8],Lines[9],Lines[10],Lines[11],\n",
        "                       Lines[12],Lines[13],Lines[14],Lines[15]],fontsize=15,\n",
        "              frameon=False,bbox_to_anchor=(1.4, 0.8),bbox_transform=ax.transAxes)\n",
        "\n",
        " \n",
        "figMDS.savefig(str(output_path / 'MDSSpace.png'), dpi=300)\n",
        "figMDS.savefig(str(output_path /'MDSSpace.svg'), format=\"svg\")\n",
        "\n",
        "# Save results form the embedding to be used in the remaining analysis\n",
        "pickle.dump(data_reduced, open(str(output_path / \"embeddings.p\"), \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y19DU5UH_EWC",
        "colab_type": "text"
      },
      "source": [
        "## Analyse the neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x25diSb_IFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from helperfunction import (get_models_neighbours, get_dissimilarity_n_neighbours\n",
        "                            get_null_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOAQ8O518_cP",
        "colab": {}
      },
      "source": [
        "N = 544\n",
        "n_neighbors_step = 10\n",
        "\n",
        "neighbours_orig, adj_array = get_models_neighbours(N, n_neighbors_step, X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyfPmC_wNumB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbours_tsne, _ = get_models_neighbours(N, n_neighbors_step,\n",
        "                                           data_reduced['t-SNE'])\n",
        "diss_tsne = get_dissimilarity_n_neighbours(neighbours_orig, neighbours_tsne)\n",
        "del neighbours_tsne "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16BQTmevzoue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbours_lle, _ = get_models_neighbours(N, n_neighbors_step, \n",
        "                                          data_reduced['LLE'])\n",
        "diss_lle = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_lle)\n",
        "del neighbours_lle "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phtJnBWCz1l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbours_se, _ = get_models_neighbours(N, n_neighbors_step,\n",
        "                                         data_reduced['SE'])\n",
        "diss_se = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_se)\n",
        "del neighbours_se"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r92E3fm3z6HC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neighbours_mds, _ = get_models_neighbours(N, n_neighbors_step,\n",
        "                                          data_reduced['MDS'])\n",
        "diss_mds = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_mds)\n",
        "del neighbours_mds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaxUNFasas6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "null_distribution = get_null_distribution(N, n_neighbors_step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od_KIcl-bm_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the dissimilarity of the random distribution\n",
        "diss_random = get_dissimilarity_n_neighbours(neighbours_orig, random_nn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5XUNH1My_cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "n_neighbours = range(2, N, n_neighbors_step)\n",
        "ax.plot(n_neighbours, diss_tsne, label='t-SNE', color='#1DACE8')\n",
        "ax.plot(n_neighbours, diss_lle, label='LLE', color='#E5C4A1')\n",
        "ax.plot(n_neighbours, diss_se, label='SE', color='#F24D29')\n",
        "ax.plot(n_neighbours, diss_mds, label='MDS', color='#1C366B')\n",
        "plt.plot(n_neighbours, null_distribution, label='random', c='grey')\n",
        "#plt.plot(n_neighbours, diss_random, label='random_rnd', c='k')\n",
        "plt.ylim([0,1])\n",
        "plt.xlim([0,N])\n",
        "plt.legend(frameon=False)\n",
        "plt.xlabel('$k$ Nearest Neighbors')\n",
        "plt.ylabel('Dissimilarity $\\epsilon_k$')\n",
        "plt.savefig(str(output_path / 'dissimilarity_all.svg'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4sodQ_wC4pY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download file to computer\n",
        "from google.colab import files\n",
        "files.download(str(output_path / 'dissimilarity_all.svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yM3HTB58LA",
        "colab_type": "text"
      },
      "source": [
        "## Exhaustive Search\n",
        "\n",
        "Exhaustive search for SVR prediction of age, so we know what \"ground truth\" is.\n",
        "\n",
        "Note: This step is time consuming and might take about 4hrs hrs to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNBlUjI6Nwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt import BayesianOptimization, UtilityFunction\n",
        "from helperfunctions import objectiveFunc, bayesian_optimisation, display_gp_mean_uncertainty\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLz4M0z4Ljj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load embedding results. This cell is only necessary if you are running this\n",
        "# part of the analysis separatly.\n",
        "ModelEmbeddings = pickle.load(open(str(output_path / \"embeddings.p\"), \"rb\" ) )\n",
        "ModelEmbedding = ModelEmbeddings['MDS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib3ZKhDMmPcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PredictedAcc = np.zeros((len(Data_Run)))\n",
        "\n",
        "for i in tqdm(range(len(Data_Run))):\n",
        "    tempPredAcc = objectiveFunc(i, AgesPrediction, Sparsities_Run, Data_Run,\n",
        "                              BCT_models, BCT_Run, KeptYeoIDs, MainNoNanPrediction,\n",
        "                              GSRNoNanPrediction, 1)\n",
        "    PredictedAcc[i] = tempPredAcc\n",
        "\n",
        "#Display how predicted accuracy is distributed across the low-dimensional space\n",
        "plt.scatter(ModelEmbedding[0: PredictedAcc.shape[0], 0],\n",
        "            ModelEmbedding[0: PredictedAcc.shape[0], 1],\n",
        "            c=PredictedAcc)\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aVnBYeLmQxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dump accuracies\n",
        "pickle.dump(PredictedAcc, open(str(output_path / 'predictedAcc.pckl'), 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfOFZKFyCiJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download file to computer\n",
        "from google.colab import files\n",
        "files.download(str(output_path / 'predictedAcc.pckl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7UX0xYsKAdl",
        "colab_type": "text"
      },
      "source": [
        "## Active Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8aTNtvW3zp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "import pickle\n",
        "\n",
        "from matplotlib import cm\n",
        "import bct\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import permutation_test_score\n",
        "\n",
        "\n",
        "\n",
        "from helperfunctions import (initialize_bo, run_bo, posterior, \n",
        "                             posteriorOnlyModels, display_gp_mean_uncertainty,\n",
        "                             plot_bo_estimated_space, plot_bo_evolution,\n",
        "                             analysis_space)\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn0TpiIuBSdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define paths\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "data_path = PROJECT_ROOT / 'test' /'data'\n",
        "output_path = PROJECT_ROOT / 'test' / 'output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih9A4B4CIyYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load embedding results. This cell is only necessary if you are running this\n",
        "# part of the analysis separatly.\n",
        "ModelEmbeddings = pickle.load(open(str(output_path / \"embeddings.p\"), \"rb\" ))\n",
        "ModelEmbedding = ModelEmbeddings['MDS']\n",
        "\n",
        "PredictedAcc = pickle.load(open(str(output_path / \"predictedAcc.pckl\"), \"rb\"))\n",
        "\n",
        "ModelResults = pickle.load(open(str(output_path / \"ModelsResults.p\"), \"rb\" ))\n",
        "Results = ModelResults['ResultsIndVar']\n",
        "BCT_Run = ModelResults['BCT']\n",
        "Sparsities_Run = ModelResults['Sparsities']\n",
        "Data_Run = ModelResults['Data']\n",
        "GroupSummary = ModelResults['SummaryStat']\n",
        "#AgesPrediction = ModelResults['AgesPrediction']\n",
        "#KeptYeoIDs = ModelResults['KeptYeoIDs']\n",
        "#GSRNoNanPrediction = ModelResults['GSRNoNanPrediction']\n",
        "#MainNoNanPrediction = ModelResults['MainNoNanPrediction']\n",
        "#BCT_models = ModelResults['BCT_models]\n",
        "\n",
        "#Ages = np.asarray(data1['age.main'])\n",
        "preprocessing = ['MRS', 'GRS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3pdTLOC_WU4",
        "colab_type": "text"
      },
      "source": [
        "### Exploratory analysis\n",
        "\n",
        "Note: This step takes about 30min."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l81tOZ9Z33WD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kappa = 10\n",
        "\n",
        "# Define settins for the analysis\n",
        "kernel, optimizer, utility, init_points, n_iter, pbounds, nbrs, RandomSeed = \\\n",
        "                      initialize_bo(ModelEmbedding, kappa)\n",
        "\n",
        "# Perform optimization. Given that the space is continuous and the analysis \n",
        "# approaches are not, we penalize suggestions that are far from any actual \n",
        "# analysis approaches. For these suggestions the registered value is set to the\n",
        "#  lowest value from the burn in. These points (BadIters) are only used\n",
        "# during search but exluded when recalculating the GP regression after search.\n",
        "BadIter = run_bo(kernel, optimizer, utility, init_points,\n",
        "                 n_iter, pbounds, nbrs, RandomSeed,\n",
        "                 ModelEmbedding, BCT_models,BCT_Run,\n",
        "                 Sparsities_Run,Data_Run,AgesPrediction,\n",
        "                 KeptYeoIDs, MainNoNanPrediction,\n",
        "                 GSRNoNanPrediction,1, MultivariateUnivariate=True, verbose=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSUlVAr3LQa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_exploratory, y_exploratory, z_exploratory, x, y, gp, vmax, vmin = \\\n",
        "                                           plot_bo_estimated_space(kappa, BadIter,\n",
        "                                              optimizer, pbounds, \n",
        "                                              ModelEmbedding, PredictedAcc, \n",
        "                                              kernel, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQOakRcjLTCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the results of the active search and the evolution of the search\n",
        "# after 5, 10,20, 30 and 50 iterations.\n",
        "plot_bo_evolution(kappa, x_exploratory, y_exploratory, z_exploratory, x, y, gp,\n",
        "                  vmax, vmin, ModelEmbedding, PredictedAcc, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gchNrIvexHA",
        "colab_type": "text"
      },
      "source": [
        "### Exploitatory analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVoIxA3173sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kappa = .1\n",
        "\n",
        "# Define settins for the analysis\n",
        "kernel, optimizer, utility, init_points, n_iter, pbounds, nbrs, RandomSeed = \\\n",
        "                      initialize_bo(ModelEmbedding, kappa)\n",
        "\n",
        "# Perform optimization. Given that the space is continuous and the analysis \n",
        "# approaches are not, we penalize suggestions that are far from any actual \n",
        "# analysis approaches. For these suggestions the registered value is set to the\n",
        "#  lowest value from the burn in. These points (BadIters) are only used\n",
        "# during search but exluded when recalculating the GP regression after search.\n",
        "BadIter = run_bo(kernel, optimizer, utility, init_points,\n",
        "                 n_iter, pbounds, nbrs, RandomSeed,\n",
        "                 ModelEmbedding, BCT_models,BCT_Run,\n",
        "                 Sparsities_Run,Data_Run,AgesPrediction,\n",
        "                 KeptYeoIDs, MainNoNanPrediction,\n",
        "                 GSRNoNanPrediction,1, MultivariateUnivariate=True, verbose=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rijtkCYjfGa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_exploratory, y_exploratory, z_exploratory, x, y, gp, vmax, vmin = \\\n",
        "                                           plot_bo_estimated_space(kappa, BadIter,\n",
        "                                              optimizer, pbounds, \n",
        "                                              ModelEmbedding, PredictedAcc, \n",
        "                                              kernel, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7DbkSuNfJjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display the results of the active search and the evolution of the search\n",
        "# after 5, 10,20, 30 and 50 iterations.\n",
        "plot_bo_evolution(kappa, x_exploratory, y_exploratory, z_exploratory, x, y, gp,\n",
        "                  vmax, vmin, ModelEmbedding, PredictedAcc, output_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyc9XH6ufdzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download file to computer\n",
        "from google.colab import files\n",
        "files.download(str(output_path / 'BOptEvolutionK10.svg'))\n",
        "files.download(str(output_path / 'BOptEvolutionK0.1.svg'))\n",
        "files.download(str(output_path / 'BOptAndTrueK0.1.svg'))\n",
        "files.download(str(output_path / 'BOptAndTrueK10.svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8prbJVG3Z6M",
        "colab_type": "text"
      },
      "source": [
        "### Repetitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMD8DNNKLxNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernel = 1.0 * Matern(length_scale=25, length_scale_bounds=(10,80),nu=2.5) \\\n",
        "    + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 0.1))\n",
        "\n",
        "lb1 = np.min(ModelEmbedding[:, 0])\n",
        "hb1 = np.max(ModelEmbedding[:, 0])\n",
        "lb2 = np.min(ModelEmbedding[:, 1])\n",
        "hb2 = np.max(ModelEmbedding[:, 1])\n",
        "pbounds = {'b1': (lb1, hb1), 'b2': (lb2, hb2)}\n",
        "\n",
        "n_repetitions = 20\n",
        "BestModelGPSpace=np.zeros(n_repetitions)\n",
        "BestModelGPSpaceModIndex=np.zeros(n_repetitions)\n",
        "BestModelEmpirical=np.zeros(n_repetitions)\n",
        "BestModelEmpiricalModIndex=np.zeros(n_repetitions)\n",
        "ModelActualAccuracyCorrelation=np.zeros(n_repetitions)\n",
        "CVPValBestModels=np.zeros(n_repetitions)\n",
        "\n",
        "for DiffInit in range(n_repetitions):\n",
        "    optimizer = BayesianOptimization(f=None,\n",
        "                                     pbounds=pbounds,\n",
        "                                     verbose=4,\n",
        "                                     random_state=166+DiffInit)\n",
        "\n",
        "    optimizer.set_gp_params(kernel=kernel,normalize_y=True,\n",
        "                            n_restarts_optimizer=10)\n",
        "\n",
        "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(ModelEmbedding)\n",
        "\n",
        "    distances, indices = nbrs.kneighbors(ModelEmbedding)\n",
        "\n",
        "    utility = UtilityFunction(kind=\"ucb\", kappa=10,xi=1e-1)\n",
        "\n",
        "\n",
        "    n_iter=10\n",
        "    init_points=10\n",
        "    RandomSeed=111+DiffInit\n",
        "    np.random.seed(RandomSeed)\n",
        "    FailedIters=bayesian_optimisation(kernel, optimizer, utility, init_points,\n",
        "                                      n_iter, pbounds, nbrs,RandomSeed,\n",
        "                                      ModelEmbedding,BCT_models,BCT_Run,\n",
        "                                      Sparsities_Run,Data_Run,AgesPrediction,\n",
        "                                      KeptYeoIDs,MainNoNanPrediction,\n",
        "                                      GSRNoNanPrediction,1,-1)\n",
        "    \n",
        "    gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True,\n",
        "                                  n_restarts_optimizer=10)\n",
        "\n",
        "    x_temp = np.array([[res[\"params\"][\"b1\"]] for res in optimizer.res])\n",
        "    y_temp = np.array([[res[\"params\"][\"b2\"]] for res in optimizer.res])\n",
        "    z_temp = np.array([res[\"target\"] for res in optimizer.res])\n",
        "\n",
        "    x_obs=x_temp[FailedIters==0]\n",
        "    y_obs=y_temp[FailedIters==0]\n",
        "    z_obs=z_temp[FailedIters==0]\n",
        "    \n",
        "    muModEmb,sigmaModEmb,gpModEmb=posteriorOnlyModels(gp, x_obs, y_obs, z_obs,\n",
        "                                                      ModelEmbedding)\n",
        "    \n",
        "    BestModelGPSpace[DiffInit]=muModEmb.max()\n",
        "    BestModelGPSpaceModIndex[DiffInit]=muModEmb.argmax()\n",
        "    BestModelEmpirical[DiffInit]=z_obs.max()\n",
        "    Model_coord = np.array([[x_obs[z_obs.argmax()][-1], y_obs[z_obs.argmax()][-1]]])\n",
        "    BestModelEmpiricalModIndex[DiffInit]=nbrs.kneighbors(Model_coord)[1][0][0]\n",
        "    ModelActualAccuracyCorrelation[DiffInit]=spearmanr(muModEmb,PredictedAcc)[0]\n",
        "    \n",
        "    ClassOrRegress=1\n",
        "    TempModelNum=muModEmb.argmax()\n",
        "    Y=AgesPrediction\n",
        "    CommunityIDs=KeptYeoIDs\n",
        "    if Data_Run[TempModelNum]=='MRS':\n",
        "        TempData=MainNoNanPrediction # BUG BUG BUG \n",
        "        TotalRegions=346\n",
        "        TotalSubjects=TempData.shape[2]\n",
        "    elif Data_Run[TempModelNum]=='GRS':\n",
        "        TempData=GSRNoNanPrediction\n",
        "        TotalRegions=346\n",
        "        TotalSubjects=TempData.shape[2]   \n",
        "    \n",
        "    TempThreshold=Sparsities_Run[TempModelNum]\n",
        "    BCT_Num = BCT_Run[TempModelNum]\n",
        "    #BCT_Num=[i for i, e in enumerate(BCT_models) if e[0] == BCT_Run[TempModelNum]][0]\n",
        "    \n",
        "    TempResults=np.zeros([TotalSubjects, n_regions])\n",
        "    for SubNum in range(0,TotalSubjects):\n",
        "        ss = analysis_space(BCT_Num, BCT_models, x, KeptYeoIDs)\n",
        "        TempResults[SubNum,:] = ss \n",
        "    scaler = StandardScaler()\n",
        "    TempResults=scaler.fit_transform(TempResults)\n",
        "  \n",
        "    model = SVR(C=1.0, epsilon=0.2)\n",
        "    #rs = np.random.RandomState(100)\n",
        "    TempScore=permutation_test_score(model, TempResults, AgesPrediction.ravel(),\n",
        "                                     groups=None, cv=None, n_permutations=5000, \n",
        "                                     n_jobs=None, random_state=5, verbose=0,\n",
        "                                     scoring=\"neg_mean_absolute_error\")\n",
        "    CVPValBestModels[DiffInit]=TempScore[2]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_0lraz1fCt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEMP\n",
        "results = {}\n",
        "results['ModelEmbedding'] = ModelEmbedding\n",
        "results['BestModelGPSpaceModIndex'] = BestModelGPSpaceModIndex\n",
        "results['BestModelEmpiricalModIndex'] = BestModelEmpiricalModIndex\n",
        "results['BestModelEmpirical'] = BestModelEmpirical\n",
        "results['ModelActualAccuracyCorrelation'] = ModelActualAccuracyCorrelation\n",
        "results['TempResults'] = TempResults\n",
        "pickle.dump(results, open(str(output_path / 'results.pckl'), 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW3I6hZRgTvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download file to computer\n",
        "from google.colab import files\n",
        "files.download(str(output_path / 'results.pckl'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtFixm7SA_N6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PredictedAcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMqeSsZlL28V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# displaying results of 20 iterations\n",
        "\n",
        "fig8 = plt.figure(constrained_layout=False,figsize=(18,6))\n",
        "gs1 = fig8.add_gridspec(nrows=6, ncols=18)\n",
        "ax1 = fig8.add_subplot(gs1[:,0:6])\n",
        "ax1.set_title('Optima GP regression: 20 iterations',fontsize=15,fontweight=\"bold\")\n",
        "ax1.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],\n",
        "            ModelEmbedding[0:PredictedAcc.shape[0],1],\n",
        "            c=PredictedAcc*10,cmap='coolwarm',alpha=0.2,s=120)#vmax=vmax,vmin=vmin,\n",
        "ax1.scatter(ModelEmbedding[BestModelGPSpaceModIndex.astype(int)][:,0],\n",
        "            ModelEmbedding[BestModelGPSpaceModIndex.astype(int)][:,1],s=120,c='black')\n",
        "\n",
        "ax1.set_xlim(-50, 50)\n",
        "ax1.set_ylim(-50, 50)\n",
        "\n",
        "ax2 = fig8.add_subplot(gs1[:,7:13])\n",
        "ax2.set_title('Empirical optima: 20 iterations',fontsize=15,fontweight=\"bold\")\n",
        "ax2.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],\n",
        "            ModelEmbedding[0:PredictedAcc.shape[0],1],\n",
        "            c=PredictedAcc*10,cmap='coolwarm',s=120,alpha=0.2)#vmax=vmax,vmin=vmin,\n",
        "ax2.scatter(ModelEmbedding[BestModelEmpiricalModIndex.astype(int)][:,0],\n",
        "            ModelEmbedding[BestModelEmpiricalModIndex.astype(int)][:,1],c='black',s=120)\n",
        "\n",
        "ax2.set_xlim(-50, 50)\n",
        "ax2.set_ylim(-50, 50)\n",
        "\n",
        "ax3 = fig8.add_subplot(gs1[:,14:16])\n",
        "ax3.violinplot([PredictedAcc*10,BestModelEmpirical*10])\n",
        "ax3.set_xticks([1, 2])\n",
        "ax3.set_xticklabels(['Accuracy \\n of all points', 'Accuracy\\n of optima'],fontsize=9)\n",
        "\n",
        "ax4 = fig8.add_subplot(gs1[:,17:18])\n",
        "ax4.violinplot([ModelActualAccuracyCorrelation])\n",
        "ax4.set_xticks([1])\n",
        "ax4.set_xticklabels(['Correlation: \\n est vs emp '],fontsize=9)\n",
        "\n",
        "gs1\n",
        "fig8.savefig(str(output_path / 'BOpt20Repeats.png'),dpi=300) \n",
        "fig8.savefig(str(output_path / 'BOpt20Repeats.svg'),format=\"svg\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP_RnG9Dgb-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}