{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lHW7cYvz0a74"
   },
   "source": [
    "# Setting up the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4670,
     "status": "ok",
     "timestamp": 1597654603112,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "BzOXabS-wOg3",
    "outputId": "40ac915b-6ff9-4512-918c-bd13ad09fc2d"
   },
   "outputs": [],
   "source": [
    "# Cloning the git repo with the data structure\n",
    "!git clone https://github.com/JessyD/test.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66429,
     "status": "ok",
     "timestamp": 1597654665016,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "YtCBYS1Q07ZK",
    "outputId": "ef331b4d-29c9-473a-ec82-09003203fb87"
   },
   "outputs": [],
   "source": [
    "# Install necessary python dependencies\n",
    "! pip install -r test/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1tU-46g1f72"
   },
   "source": [
    "# Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79037,
     "status": "ok",
     "timestamp": 1597654682350,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "WVOQ5bQxoL-e",
    "outputId": "ca1cf4d8-7838-450c-d4ff-00aa76b76a5f"
   },
   "outputs": [],
   "source": [
    "!wget -O test/data/nspn.fmri.main.RData https://ndownloader.figshare.com/files/20958708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34105,
     "status": "ok",
     "timestamp": 1596537790528,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "16eWfSDM1uSU",
    "outputId": "fe9a3daf-9324-4c66-d50c-31ce5f2830e4"
   },
   "outputs": [],
   "source": [
    "!wget -O test/data/nspn.fmri.gsr.RData https://ndownloader.figshare.com/files/20958699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105005,
     "status": "ok",
     "timestamp": 1596537863215,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "YC9v-PY82lun",
    "outputId": "651ad41d-1125-4e8d-9e6d-e5016447e89b"
   },
   "outputs": [],
   "source": [
    "!wget -O test/data/nspn.fmri.lowmot.RData https://ndownloader.figshare.com/files/20958702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105552,
     "status": "ok",
     "timestamp": 1596537866489,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "RPaw6pyIhy4g",
    "outputId": "d46dfb30-35f4-4f10-b455-81ac05e90b9b"
   },
   "outputs": [],
   "source": [
    "!wget -O test/data/nspn.fmri.general.vars.RData https://ndownloader.figshare.com/files/20819796"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBm5C8HB3Okj"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1948,
     "status": "ok",
     "timestamp": 1597655101389,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "Ra4NkHs2gjlH"
   },
   "outputs": [],
   "source": [
    "import pyreadr \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import matplotlib.colorbar\n",
    "import bct\n",
    "import pickle\n",
    "from sklearn_rvm import EMRVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import plotly.express as px\n",
    "from numpy.random import default_rng\n",
    "\n",
    "from scipy import stats\n",
    "from numpy.random import RandomState\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1597655102900,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "kQR-qpAVhTz0"
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "np.random.seed(2)\n",
    "rng = default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1597655104744,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "mapfQZqEixXl"
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "from pathlib import Path\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "data_path = PROJECT_ROOT / 'test' /'data'\n",
    "output_path = PROJECT_ROOT / 'test' / 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7021,
     "status": "ok",
     "timestamp": 1597655112435,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "he7t6Vu6omM1"
   },
   "outputs": [],
   "source": [
    "data1 = pyreadr.read_r(str(data_path / 'nspn.fmri.main.RData'))\n",
    "#genVar = pyreadr.read_r(str(data_path / 'nspn.fmri.general.vars.RData'))\n",
    "#data2 = pyreadr.read_r(str(data_path / 'nspn.fmri.gsr.RData'))\n",
    "#data3 = pyreadr.read_r(str(data_path / 'nspn.fmri.lowmot.RData'))\n",
    "\n",
    "DataNames=['nspn.fmri.main.RData','nspn.fmri.gsr.RData','nspn.fmri.lowmot.RData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2582,
     "status": "error",
     "timestamp": 1597654785925,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "s1Gv0TyC25o8",
    "outputId": "494feeca-937b-423b-f798-00ce3b7f4045"
   },
   "outputs": [],
   "source": [
    "#Get motion regression functional connectivity data and reshape into region x region x subject array\n",
    "FC=np.asarray(data1['fc.main'])\n",
    "MainNoNan = np.nan_to_num(FC,copy=True,nan=1.0)\n",
    "MainNoNanReshape=np.reshape(MainNoNan,[346,346,520],order='F')\n",
    "\n",
    "#Get global signal regression functional connectivity data and reshape into region x region x subject arra\n",
    "\n",
    "FC=np.asarray(data2['fc.gsr'])\n",
    "GSRNoNan = np.nan_to_num(FC,copy=True,nan=1.0)\n",
    "GSRNoNanReshape=np.reshape(GSRNoNan,[346,346,520],order='F')\n",
    "\n",
    "#Read in subject IDs and age\n",
    "IDMain=np.asarray(data1['id.main'])\n",
    "Ages=np.asarray(data1['age.main'])\n",
    "\n",
    "#Find unique subject IDs and index of first instance and find FC data corresponding to these indices\n",
    "IDs,IDIndexUnique=np.unique(IDMain,return_index=True)\n",
    "MainNoNanReshapeUnique=MainNoNanReshape[:,:,IDIndexUnique]\n",
    "GSRNoNanReshapeUnique=GSRNoNanReshape[:,:,IDIndexUnique]\n",
    "AgesUnique=Ages[IDIndexUnique]\n",
    "\n",
    "#Number of randomly selected subjects to be used to define the low-dimensional space then split FC data and age data into two: 50 for defining space and remaining 248 for subsequent prediction\n",
    "SpaceDefineN=50\n",
    "RandomIndexes = rng.choice(IDs.shape[0], size=IDs.shape[0], replace=False)\n",
    "MainNoNanModelSpace=MainNoNanReshapeUnique[:,:,RandomIndexes[0:SpaceDefineN]]\n",
    "MainNoNanPrediction=MainNoNanReshapeUnique[:,:,RandomIndexes[SpaceDefineN:]]\n",
    "GSRNoNanModelSpace=GSRNoNanReshapeUnique[:,:,RandomIndexes[0:SpaceDefineN]]\n",
    "GSRNoNanPrediction=GSRNoNanReshapeUnique[:,:,RandomIndexes[SpaceDefineN:]]\n",
    "AgesModelSpace=AgesUnique[RandomIndexes[0:SpaceDefineN]]\n",
    "AgesPrediction=AgesUnique[RandomIndexes[SpaceDefineN:]]\n",
    "IDsModelSpace=IDs[RandomIndexes[0:SpaceDefineN]] \n",
    "IDsPrediction=IDs[RandomIndexes[SpaceDefineN:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DAI4LaEsydR"
   },
   "outputs": [],
   "source": [
    "#Get info about brain regions and find Yeo network IDs; useful later on for graph metrics that need community labels.\n",
    "KeptIDs=np.asarray(genVar['hcp.keep.id'])\n",
    "YeoIDs=np.asarray(genVar['yeo.id.subc'])\n",
    "KeptYeoIDs=YeoIDs[KeptIDs-1][:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79k8wv4MhhnK"
   },
   "outputs": [],
   "source": [
    "#Dictionary of 16 graph theory measures taken from the Brain Connectivity Toolbox\n",
    "\n",
    "BCT_models = [\n",
    "    ('00_Undirected_degree', bct.degrees_und),\n",
    "    ('01_Undirected_strength', bct.strengths_und),\n",
    "    ('02_Betweeness_Bin', bct.betweenness_bin),\n",
    "    ('03_Clust_Bu', bct.clustering_coef_bu),\n",
    "    ('04_Clust_Wu', bct.clustering_coef_wu),\n",
    "    ('05_EigenvectorC', bct.eigenvector_centrality_und),\n",
    "    ('06_SubgraphC', bct.subgraph_centrality),\n",
    "    ('07_LocalEfficiencyC', bct.efficiency_bin),\n",
    "    ('08_ModularityLouvain', bct.modularity_louvain_und),\n",
    "    ('09_ModularityProbTune', bct.modularity_probtune_und_sign),\n",
    "    ('10_ParticipationCoef', bct.participation_coef),\n",
    "    ('11_ModuleDegreeZScore', bct.module_degree_zscore),\n",
    "    ('12_PagerankCentrality', bct.pagerank_centrality),\n",
    "    ('13_DiversityCoef', bct.diversity_coef_sign),\n",
    "    ('14_GatewayDegree',bct.gateway_coef_sign),\n",
    "    ('15_KCoreCentrality',bct.kcoreness_centrality_bu),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5mCueTin-12"
   },
   "source": [
    "## Generating data to build low-dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "puxCTglyiKVF"
   },
   "outputs": [],
   "source": [
    "#This involves exhaustive evaluation of all 544 analysis approaches.  \n",
    "TotalRegions=346\n",
    "Results={}\n",
    "BCT_Run={}\n",
    "Sparsities_Run={}\n",
    "Data_Run={}\n",
    "GroupSummary={}\n",
    "Results=np.array([])\n",
    "ResultsIndVar=np.array([])\n",
    "\n",
    "count=0\n",
    "for DataPreproc in range(0,2): # data preprocessing\n",
    "    if DataPreproc==0:\n",
    "        TempData=MainNoNanModelSpace\n",
    "        TotalRegions=346\n",
    "        TotalSubjects=TempData.shape[2]\n",
    "    elif DataPreproc==1:\n",
    "        TempData=GSRNoNanModelSpace\n",
    "        TotalRegions=346\n",
    "        TotalSubjects=TempData.shape[2]\n",
    "\n",
    "    for TempThreshold in [0.4,0.3,0.25,0.2,0.175,0.150,0.125,0.1,0.09,0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]: # FC threshold level\n",
    "\n",
    "        for BCT_Num in range(0,16): # Graph theory measure\n",
    "        \n",
    "            TempResults=np.zeros([TotalSubjects,TotalRegions])\n",
    "            for SubNum in range(0,TotalSubjects):\n",
    "                x = bct.threshold_proportional(TempData[:,:,SubNum], TempThreshold, copy=True)\n",
    "                if BCT_Num==7:\n",
    "                    s=np.asarray(BCT_models[BCT_Num][1](x,1))\n",
    "                elif BCT_Num==8:\n",
    "                    temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "                    s=temp_s[0]\n",
    "                elif BCT_Num==9:\n",
    "                    temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "                    s=temp_s[0]\n",
    "                elif BCT_Num==10:\n",
    "                    s=np.asarray(BCT_models[BCT_Num][1](x,KeptYeoIDs))\n",
    "                elif BCT_Num==11:\n",
    "                    s=np.asarray(BCT_models[BCT_Num][1](x,KeptYeoIDs))\n",
    "                elif BCT_Num==12:\n",
    "                    s=np.asarray(BCT_models[BCT_Num][1](x,0.85))\n",
    "     \n",
    "                elif BCT_Num==13:\n",
    "                    temp_s=np.asarray(BCT_models[BCT_Num][1](x,KeptYeoIDs))\n",
    "                    s=temp_s[0] \n",
    "                elif BCT_Num==14:\n",
    "                    temp_s=np.asarray(BCT_models[BCT_Num][1](x,KeptYeoIDs))\n",
    "                    s=temp_s[0] \n",
    "                elif BCT_Num==15:\n",
    "                    temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "                    s=temp_s[0]\n",
    "                else:\n",
    "                    s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "                TempResults[SubNum,:]=s #For each subject for each approach keep the 346 regional values.        \n",
    "\n",
    "            BCT_Run[count]=BCT_models[BCT_Num][0];\n",
    "            Sparsities_Run[count]=TempThreshold\n",
    "            Data_Run[count]=DataPreproc\n",
    "            GroupSummary[count]='Mean'\n",
    "            cos_sim=cosine_similarity(TempResults,TempResults) #Build an array of similarities between subjects for each analysis approach \n",
    "\n",
    "            if Results.size == 0:\n",
    "                Results=np.mean(TempResults,axis=0)\n",
    "                ResultsIndVar=np.asarray(list(cos_sim[np.triu_indices(TotalSubjects,k = 1)])).T #Keep the upper triangle of similarity matrix, reshape to a 1D vector resulting a 2D array of between subject similarities x analysis approach \n",
    "            else:\n",
    "                Results=np.vstack((Results,np.mean(TempResults,axis=0)))\n",
    "                ResultsIndVar=np.vstack((ResultsIndVar,np.asarray(list(cos_sim[np.triu_indices(TotalSubjects,k = 1)]))))\n",
    "            count=count+1\n",
    "            \n",
    "\n",
    "            \n",
    "ModelsResults={\"Results\": Results, \"ResultsIndVar\": ResultsIndVar, \"BCT\": BCT_Run,\"Sparsities\": Sparsities_Run, \"Data\": Data_Run, \"SummaryStat\": GroupSummary}\n",
    "            \n",
    "pickle.dump( ModelsResults, open(str(output_path / \"ModelsResults.p\"), \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxVWimqHnyM0"
   },
   "source": [
    "## Building the low-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUYIJG675JWn"
   },
   "source": [
    "### LLE, SE, tSNE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10304,
     "status": "ok",
     "timestamp": 1597655123171,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "M6sfdK1TiiVA",
    "outputId": "d53e194a-d0fb-49e0-e251-6e087f5edfc3"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ModelResults=pickle.load(open(str(output_path / \"ModelsResults.p\"), \"rb\" ) )\n",
    "Results=ModelResults['ResultsIndVar']\n",
    "BCT_Run=ModelResults['BCT']\n",
    "Sparsities_Run=ModelResults['Sparsities']\n",
    "Data_Run=ModelResults['Data']\n",
    "GroupSummary=ModelResults['SummaryStat']\n",
    "Ages=np.asarray(data1['age.main'])\n",
    "\n",
    "#Scale the data prior to dimensionality reduction\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(Results.T)\n",
    "\n",
    "X=X.T\n",
    "\n",
    "n_neighbors = 20\n",
    "n_components = 2 #number of components requested. In this case for a 2D space.\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "#Define different dimensionality reduction techniques \n",
    "LLE = partial(manifold.LocallyLinearEmbedding,\n",
    "              n_neighbors, n_components, eigen_solver='dense')\n",
    "\n",
    "methods = OrderedDict()\n",
    "methods['LLE'] = LLE(method='standard')\n",
    "methods['SE'] = manifold.SpectralEmbedding(n_components=n_components,n_neighbors=n_neighbors)\n",
    "methods['t-SNE'] = manifold.TSNE(n_components=n_components, init='pca',random_state=0)\n",
    "#methods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=10, random_state=21,metric=True)\n",
    "\n",
    "\n",
    "markers=[\"x\",\"s\",\"o\",\"*\",\"D\",\"1\",\"v\",\"p\",\"H\",\"+\",\"|\",\"_\",\"3\",\"^\",\"4\",\"<\",\"X\"]\n",
    "colourmaps=[\"Oranges\",\"Purples\",\"Greens\"]\n",
    "BCT = np.array(list(BCT_Run.items()))[:,1]\n",
    "Sparsities = np.array(list(Sparsities_Run.items()))[:,1]\n",
    "Data=np.array(list(Data_Run.items()))[:,1]\n",
    "\n",
    "# Reduced dimensions\n",
    "data_reduced = {}\n",
    "\n",
    "fig.subplots_adjust(right=0.7)\n",
    "figDE = plt.figure(constrained_layout=False,figsize=(21,6))\n",
    "gsDE = figDE.add_gridspec(nrows=6, ncols=21)#, left=0.05, right=0.48, wspace=0.05)\n",
    "\n",
    "#Perform embedding and plot the results (including info about the approach in the color/intensity and shape).\n",
    "\n",
    "for i, (label, method) in enumerate(methods.items()):\n",
    "     \n",
    "    t0 = time()\n",
    "    Y = method.fit_transform(X)\n",
    "\n",
    "    t1 = time()\n",
    "    # Save the results\n",
    "    data_reduced[label] = Y\n",
    "    \n",
    "    ax = figDE.add_subplot(gsDE[:,i*6+i:(i+1)*6+i])\n",
    "    for j, d in enumerate(np.unique(Data)):\n",
    "\n",
    "        BCTTemp=BCT[Data==d]\n",
    "        SparsitiesTemp=Sparsities[Data==d]\n",
    "        YTemp=Y[Data==d,:]\n",
    "\n",
    "        \n",
    "        for i, c in enumerate(np.unique(BCTTemp)):\n",
    "            im=ax.scatter(YTemp[:,0][BCTTemp==c],YTemp[:,1][BCTTemp==c],\n",
    "                          c=SparsitiesTemp[BCTTemp==c]*-0.6, marker=markers[i],\n",
    "                          cmap=colourmaps[j],s=80)\n",
    "\n",
    "    ax.set_title(\"%s \" % (label),fontsize=15,fontweight=\"bold\")\n",
    "\n",
    "    ax.axis('tight')\n",
    "\n",
    "OrangePatch = mpatches.Patch(color='orange', label='Motion Regression')\n",
    "PurplePatch = mpatches.Patch(color='purple', label='Global Signal Regression')\n",
    "\n",
    "\n",
    "Lines={}\n",
    "for i in range(0,16):\n",
    "    Lines[i] = mlines.Line2D([], [], color='black', linestyle='None',\n",
    "                             marker=markers[i],markersize=10, label=np.unique(BCT)[i])\n",
    "\n",
    "\n",
    "figDE.savefig(str(output_path / 'DifferentEmbeddings.png'),dpi=300)\n",
    "figDE.savefig(str(output_path / 'DifferentEmbeddings.svg'),format=\"svg\")\n",
    "figDE.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13212,
     "status": "ok",
     "timestamp": 1597655139103,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "Ggt7wfAfkAiD",
    "outputId": "aadd192a-0840-4e56-b171-68bd1b3919f7"
   },
   "outputs": [],
   "source": [
    "#Do the same as above but for MDS\n",
    "methods['MDS'] = manifold.MDS(n_components, max_iter=100, n_init=10, random_state=21,metric=True)\n",
    "Y = methods['MDS'].fit_transform(X)\n",
    "data_reduced['MDS'] = Y\n",
    "\n",
    "markers=[\"x\",\"s\",\"o\",\"*\",\"D\",\"1\",\"v\",\"p\",\"H\",\"+\",\"|\",\"_\",\"3\",\"^\",\"4\",\"<\",\"X\"]\n",
    "colourmaps=[\"Oranges\",\"Purples\",\"Greens\"]\n",
    "BCT = np.array(list(BCT_Run.items()))[:,1]\n",
    "Sparsities = np.array(list(Sparsities_Run.items()))[:,1]\n",
    "Data=np.array(list(Data_Run.items()))[:,1]\n",
    "\n",
    "figMDS = plt.figure(constrained_layout=False,figsize=(21,15))\n",
    "gsMDS = figMDS.add_gridspec(nrows=15, ncols=20)\n",
    "\n",
    "\n",
    "ax = figMDS.add_subplot(gsMDS[:,0:15])\n",
    "\n",
    "\n",
    "for j, d in enumerate(np.unique(Data)):\n",
    "\n",
    "    BCTTemp=BCT[Data==d]\n",
    "    SparsitiesTemp=Sparsities[Data==d]\n",
    "    YTemp=Y[Data==d,:]\n",
    "\n",
    "    for i, c in enumerate(np.unique(BCTTemp)):\n",
    "        im=ax.scatter(YTemp[:,0][BCTTemp==c],YTemp[:,1][BCTTemp==c],\n",
    "                      c=SparsitiesTemp[BCTTemp==c]*0.1, marker=markers[i]\n",
    "                      ,cmap=colourmaps[j],s=150)\n",
    "        ax.spines['top'].set_linewidth(1.5)\n",
    "        ax.spines['right'].set_linewidth(1.5)\n",
    "        ax.spines['bottom'].set_linewidth(1.5)\n",
    "        ax.spines['left'].set_linewidth(1.5)\n",
    "        ax.set_xlabel('Dimension 2',fontsize=20,fontweight=\"bold\")\n",
    "        ax.set_ylabel('Dimension 1',fontsize=20,fontweight=\"bold\")\n",
    "        ax.tick_params(labelsize=15)\n",
    "\n",
    "\n",
    "ax.set_title('Multi-dimensional Scaling', fontsize=25,fontweight=\"bold\")\n",
    "\n",
    "\n",
    "OrangePatch = mpatches.Patch(color='orange', label='Motion Regression')\n",
    "PurplePatch = mpatches.Patch(color=[85/255, 3/255, 152/255], label='Global Signal Regression')\n",
    "\n",
    "IntensityPatch1 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='Threshold: 0.4',alpha=1)\n",
    "IntensityPatch2 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='Threshold: 0.1',alpha=0.4)\n",
    "IntensityPatch3 = mpatches.Patch(color=[0.1, 0.1, 0.1], label='Threshold: 0.01',alpha=0.1)\n",
    "\n",
    "BlankLine=mlines.Line2D([], [], linestyle='None')\n",
    "\n",
    "Lines={}\n",
    "for i in range(0,16):\n",
    "    Lines[i] = mlines.Line2D([], [], color='black', linestyle='None',marker=markers[i],markersize=10, label=np.unique(BCT)[i])\n",
    "\n",
    "figMDS.legend(handles=[OrangePatch, PurplePatch,BlankLine,IntensityPatch1,IntensityPatch2, IntensityPatch3,BlankLine,Lines[0],Lines[1],Lines[2],Lines[3],Lines[4],Lines[5],Lines[6],Lines[7],Lines[8],Lines[9],Lines[10],Lines[11],Lines[12],Lines[13],Lines[14],Lines[15]],fontsize=15,frameon=False,bbox_to_anchor=(1.4, 0.8),bbox_transform=ax.transAxes)#bbox_to_anchor=(1, 1),bbox_transform=f.gcf().transFigure)\n",
    "#Keep embedding space for subsequent use in active learning below\n",
    "ModelEmbedding=Y \n",
    "figMDS.savefig(str(output_path / 'MDSSpace.png'),dpi=300)\n",
    "figMDS.savefig(str(output_path /'MDSSpace.svg'),format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y19DU5UH_EWC"
   },
   "source": [
    "## Analyse the neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1597655493631,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "2x25diSb_IFr"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "def get_dissimilarity_n_neighbours(all_neighbours_orig,\n",
    "                                   all_neighbours_reduced,\n",
    "                                   n_neighbours):\n",
    "    '''\n",
    "    Calculate the dissimilarity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_neighbours_orig:\n",
    "    all_neighbours_reduced:\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_dissimilarity: Dissimilarity scores between the original and reduced\n",
    "    space\n",
    "    '''\n",
    "\n",
    "    all_dissimilarity = []\n",
    "    for K in n_neighbours:\n",
    "        # Find the set of different indices\n",
    "        diff = set(all_neighbours_orig[K]) - set(all_neighbours_reduced[K])\n",
    "        # Calculate the dissimilarity\n",
    "        epsilon = len(diff) / len(all_neighbours_orig[K])\n",
    "        all_dissimilarity.append(epsilon)\n",
    "\n",
    "    return all_dissimilarity\n",
    "\n",
    "def get_models_neighbours(n_neigbours, data):\n",
    "    '''\n",
    "    Calculate the dissimilarity\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_neighbours: number of neighbours to analyse\n",
    "    data: data (pairwise_subjects, n_analysis)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_dissimilarity: Dissimilarity scores between the original and reduced\n",
    "    space\n",
    "    '''\n",
    "    all_adj = np.zeros((len(data), len(data), len(n_neighbours)))\n",
    "    all_neighbours_orig = []\n",
    "    \n",
    "    for idx, n_neighbour in enumerate(n_neighbours):\n",
    "        adj = kneighbors_graph(data, n_neighbour, mode='distance',\n",
    "                            metric='euclidean')\n",
    "        adj_array = adj.toarray()\n",
    "        all_adj[:, :, idx] = adj_array\n",
    "        nneighbours_orig = np.nonzero(adj_array)\n",
    "        nneighbours_orig = [item for item in zip(nneighbours_orig[0],\n",
    "                                                 nneighbours_orig[1])]\n",
    "        all_neighbours_orig.append(nneighbours_orig)\n",
    "\n",
    "    return all_neighbours_orig, all_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29713,
     "status": "ok",
     "timestamp": 1597655529906,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "VOAQ8O518_cP"
   },
   "outputs": [],
   "source": [
    "N = 544\n",
    "n_neighbours = range(2, N+1, 10)\n",
    "\n",
    "neighbours_orig, _ = get_models_neighbours(n_neighbours, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25756,
     "status": "error",
     "timestamp": 1597655180837,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -120
    },
    "id": "XyfPmC_wNumB",
    "outputId": "4778326d-77f3-4cd0-ce7f-c3705311f046"
   },
   "outputs": [],
   "source": [
    "neighbours_tsne, _ = get_models_neighbours(n_neighbours, data_reduced['t-SNE'])\n",
    "diss_tsne = get_dissimilarity_n_neighbours(neighbours_orig, neighbours_tsne,\n",
    "                                           n_neighbours)\n",
    "del neighbours_tsne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16BQTmevzoue"
   },
   "outputs": [],
   "source": [
    "neighbours_lle, _ = get_models_neighbours(n_neighbours, data_reduced['LLE'])\n",
    "diss_lle = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_lle)\n",
    "del neighbours_lle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phtJnBWCz1l6"
   },
   "outputs": [],
   "source": [
    "neighbours_se, _ = get_models_neighbours(n_neighbours, data_reduced['SE'])\n",
    "diss_se = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_se)\n",
    "del neighbours_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r92E3fm3z6HC"
   },
   "outputs": [],
   "source": [
    "neighbours_mds, _ = get_models_neighbours(n_neighbors,data_reduced['MDS'])\n",
    "diss_mds = get_dissimilarity_n_neighbours(neighbours_orig,neighbours_mds)\n",
    "del neighbours_mds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gaxUNFasas6R"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "# Calculate the null distribution\n",
    "def expectation(N,K):\n",
    "    rv = hypergeom(N, K, K)\n",
    "    x = np.arange(0, K)\n",
    "    pmf = rv.pmf(x)\n",
    "    return np.sum(x*pmf)\n",
    "\n",
    "null_distribution = []\n",
    "for K in n_neighbours:\n",
    "    E = expectation(N,K)\n",
    "    diss = 1 - (E/K)\n",
    "    null_distribution.append(diss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1596628040786,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "od_KIcl-bm_r",
    "outputId": "05ea0b50-434d-4ea9-c9fb-d8e49b76ca6e"
   },
   "outputs": [],
   "source": [
    "# Get random distribution by brutforce\n",
    "#print(len(neighbours_orig[2]), len(neighbours_orig[3]))\n",
    "random_neighbours = \n",
    "for K in n_neighbours:\n",
    "  neighbours_orig[K]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1596033934251,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "L5XUNH1My_cW",
    "outputId": "42af21b0-93d7-43e7-a31f-afa1e004c38d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(n_neighbours, diss_tsne, label='t-SNE', color='#1DACE8')\n",
    "ax.plot(n_neighbours, diss_lle, label='LLE', color='#E5C4A1')\n",
    "ax.plot(n_neighbours, diss_se, label='SE', color='#F24D29')\n",
    "ax.plot(n_neighbours, diss_mds, label='MDS', color='#1C366B')\n",
    "plt.plot(n_neighbours, null_distribution, label='random', c='grey')\n",
    "#ax.axvline(x=250, c='grey', linestyle='--', alpha=0.7)\n",
    "plt.ylim([0,1])\n",
    "plt.xlim([0,max_neig])\n",
    "plt.legend(frameon=False)\n",
    "plt.xlabel('$k$ Nearest Neighbors')\n",
    "plt.ylabel('Dissimilarity $\\epsilon_k$')\n",
    "plt.savefig(str(output_path / 'dissimilarity_all.svg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8yM3HTB58LA"
   },
   "source": [
    "## Exhaustive Search\n",
    "\n",
    "Exhaustive search for linearSVR prediction of age, so we know what \"ground truth\" is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QNBlUjI6Nwt"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "from helperfunctions import objectiveFunc,bayesian_optimisation, display_gp_mean_uncertainty\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF, ConstantKernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15431339,
     "status": "ok",
     "timestamp": 1596054887281,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "Ib3ZKhDMmPcU",
    "outputId": "c4100f5a-6ded-451b-a0f1-43521ccefcb8"
   },
   "outputs": [],
   "source": [
    "PredictedAcc=np.zeros((len(Data_Run)))\n",
    "for i in range(len(Data_Run)):\n",
    "    #print('Next Iteration:')\n",
    "    #print(i)\n",
    "    tempPredAcc=objectiveFunc(i,AgesPrediction,Sparsities_Run,Data_Run,\n",
    "                              BCT_models,BCT_Run,KeptYeoIDs,MainNoNanPrediction,\n",
    "                              GSRNoNanPrediction,1)\n",
    "    #print(tempPredAcc)\n",
    "    PredictedAcc[i]=tempPredAcc\n",
    "\n",
    "#Display how predicted accuracy is distributed across the low-dimensional space\n",
    "plt.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],ModelEmbedding[0:PredictedAcc.shape[0],1],c=PredictedAcc)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aVnBYeLmQxa"
   },
   "outputs": [],
   "source": [
    "# Dump accuracies\n",
    "pickle.dump(PredictedAcc, open(str(output_path / 'predictedAcc.pckl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v7UX0xYsKAdl"
   },
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363324,
     "status": "ok",
     "timestamp": 1596039158076,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "l81tOZ9Z33WD",
    "outputId": "ed7b56df-ed67-4222-d688-f5708602387e"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "from helperfunctions import objectiveFunc,bayesian_optimisation, display_gp_mean_uncertainty\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF, ConstantKernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "#Helper function for calculating posterior predictions only for points in the space where an analysis approach exists \n",
    "def posteriorOnlyModels(gp, x_obs, y_obs, z_obs, AllModelEmb):\n",
    "    xy = (np.array([x_obs.ravel(), y_obs.ravel()])).T\n",
    "    gp.fit(xy, z_obs)\n",
    "    mu, std = gp.predict(AllModelEmb, return_std=True)\n",
    "    return mu, std, gp\n",
    "\n",
    "\n",
    "#Define the kernel: white noise kernel plus Mattern\n",
    "kernel = 1.0 * Matern(length_scale=25, length_scale_bounds=(10,80),nu=2.5) \\\n",
    "    + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 0.1))\n",
    "\n",
    "\n",
    "\n",
    "lb1 = np.min(ModelEmbedding[:, 0])\n",
    "hb1 = np.max(ModelEmbedding[:, 0])\n",
    "lb2 = np.min(ModelEmbedding[:, 1])\n",
    "hb2 = np.max(ModelEmbedding[:, 1])\n",
    "pbounds = {'b1': (lb1, hb1), 'b2': (lb2, hb2)}\n",
    "\n",
    "\n",
    "\n",
    "#For finding nearest point in space to next suggested sample from Bayesian optimization\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(ModelEmbedding)\n",
    "\n",
    "distances, indices = nbrs.kneighbors(ModelEmbedding)\n",
    "\n",
    "#Acquisition function, in this case upper confidence bound with exploratory kappa vaalue\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=10,xi=1e-1)\n",
    "\n",
    "init_points=10 #Number of burn in random initial samples\n",
    "n_iter=40 #Number of iterations of Bayesian optimization after burn in\n",
    "\n",
    "RandomSeed=118\n",
    "\n",
    "#Initialise optimizer    \n",
    "optimizer = BayesianOptimization(f=None,\n",
    "                                pbounds=pbounds,\n",
    "                                 verbose=4,\n",
    "                                 random_state=RandomSeed)\n",
    "\n",
    "optimizer.set_gp_params(kernel=kernel,normalize_y=True,n_restarts_optimizer=10)\n",
    "np.random.seed(RandomSeed)\n",
    "\n",
    "# Perform optimization. Given that the space is continuous and the analysis \n",
    "# approaches are not, we penalize suggestions that are far from any actual \n",
    "# analysis approaches. For these suggestions the registered value is set to the\n",
    "#  lowest value from the burn in. These points (FailedIters) are only used\n",
    "# during search but exluded when recalculating the GP regression after search.\n",
    "FailedIters=bayesian_optimisation(kernel, optimizer, utility, init_points,\n",
    "                                  n_iter, pbounds, nbrs,RandomSeed,\n",
    "                                  ModelEmbedding,BCT_models,BCT_Run,\n",
    "                                  Sparsities_Run,Data_Run,AgesPrediction,\n",
    "                                  KeptYeoIDs,MainNoNanPrediction,\n",
    "                                  GSRNoNanPrediction,1,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4779,
     "status": "error",
     "timestamp": 1596039257308,
     "user": {
      "displayName": "jessica dafflon",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiuB6O3IF7wTJ_pr_q-frlYkWWiHgF13PjfyB61=s64",
      "userId": "14978032072692076907"
     },
     "user_tz": -60
    },
    "id": "qSUlVAr3LQa2",
    "outputId": "608c3f57-43b1-44ba-ddd0-4ce9ba20b4c4"
   },
   "outputs": [],
   "source": [
    "#Display the results of the active search and the evolution of the search after 5, 10,20, 30 and 50 iterations.\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import product\n",
    "\n",
    "def _posterior(gp, x_obs, y_obs, z_obs, grid_X):\n",
    "    xy = (np.array([x_obs.ravel(), y_obs.ravel()])).T\n",
    "    gp.fit(xy, z_obs)\n",
    "    mu, std = gp.predict(grid_X.reshape(-1, 2), return_std=True)\n",
    "    return mu, std, gp\n",
    "\n",
    "def posteriorOnlyModels(gp, x_obs, y_obs, z_obs, AllModelEmb):\n",
    "    xy = (np.array([x_obs.ravel(), y_obs.ravel()])).T\n",
    "    gp.fit(xy, z_obs)\n",
    "    mu, std = gp.predict(AllModelEmb, return_std=True)\n",
    "    return mu, std, gp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BadIter=FailedIters\n",
    "x = np.linspace(pbounds['b1'][0] - 10, pbounds['b1'][1] + 10, 500).reshape(\n",
    "    -1, 1)\n",
    "y = np.linspace(pbounds['b2'][0] - 10, pbounds['b2'][1] + 10, 500).reshape(\n",
    "    -1, 1)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True,\n",
    "                              n_restarts_optimizer=10)\n",
    "\n",
    "x_temp = np.array([[res[\"params\"][\"b1\"]] for res in optimizer.res])\n",
    "y_temp = np.array([[res[\"params\"][\"b2\"]] for res in optimizer.res])\n",
    "z_temp = np.array([res[\"target\"] for res in optimizer.res])\n",
    "\n",
    "x_obs=x_temp[BadIter==0]\n",
    "y_obs=y_temp[BadIter==0]\n",
    "z_obs=z_temp[BadIter==0]\n",
    "\n",
    "NumSamplesToInclude=x_obs.shape[0]\n",
    "x1x2 = np.array(list(product(x, y)))\n",
    "X0p, X1p = x1x2[:, 0].reshape(500, 500), x1x2[:, 1].reshape(500, 500)\n",
    "\n",
    "mu, sigma, gp = _posterior(gp, x_obs[0:NumSamplesToInclude], y_obs[0:NumSamplesToInclude], z_obs[0:NumSamplesToInclude], x1x2)\n",
    "\n",
    "Zmu = np.reshape(mu, (500, 500))\n",
    "Zsigma = np.reshape(sigma, (500, 500))\n",
    "\n",
    "conf0 = np.array(mu - 2 * sigma).reshape(500, 500)\n",
    "conf1 = np.array(mu + 2 * sigma).reshape(500, 500)\n",
    "\n",
    "X0p, X1p = np.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "font_dict_title = {'fontsize': 25}\n",
    "font_dict_label = {'fontsize': 15}\n",
    "font_dict_label3 = {'fontsize': 15}\n",
    "print(x_obs.shape)\n",
    "vmax=Zmu.max()\n",
    "vmin=Zmu.min()\n",
    "\n",
    "\n",
    "cm = ['coolwarm', 'seismic']\n",
    "\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "ax = ax1\n",
    "pcm = ax.pcolormesh(X0p, X1p, Zmu,vmax=vmax,vmin=vmin,cmap=cm[0],rasterized=True)  \n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(-50, 50)\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax = ax2\n",
    "pcm = ax.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],ModelEmbedding[0:PredictedAcc.shape[0],1],c=PredictedAcc,vmax=vmax,vmin=vmin,cmap=cm[0],rasterized=True)\n",
    "ax.set_aspect('equal', 'box')\n",
    "\n",
    "fig.tight_layout()\n",
    "ax.set_xlim(-50, 50)\n",
    "ax.set_ylim(-50, 50)\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.825, 0.35, 0.02, 0.3])\n",
    "\n",
    "fig.colorbar(pcm, cax=cbar_ax)\n",
    "\n",
    "\n",
    "fig.savefig(str(output_path / 'BOptAndTrueK01.png'),dpi=300)\n",
    "fig.savefig(str(output_path / 'BOptAndTrueK10.svg'),format='svg',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "font_dict_title = {'fontsize': 15}\n",
    "font_dict_label = {'fontsize': 10}\n",
    "font_dict_label3 = {'fontsize': 10}\n",
    "\n",
    "fig, axs = plt.subplots(5,3,figsize=(12,18))\n",
    "count=0\n",
    "for NumSamplesToInclude in [5,10,20,30,50]:\n",
    "\n",
    "    x1x2 = np.array(list(product(x, y)))\n",
    "    X0p, X1p = x1x2[:, 0].reshape(500, 500), x1x2[:, 1].reshape(500, 500)\n",
    "    mu, sigma, gp = _posterior(gp, x_obs[0:NumSamplesToInclude], y_obs[0:NumSamplesToInclude], z_obs[0:NumSamplesToInclude], x1x2)\n",
    "    muModEmb,sigmaModEmb,gpModEmb=posteriorOnlyModels(gp, x_obs[0:NumSamplesToInclude], y_obs[0:NumSamplesToInclude], z_obs[0:NumSamplesToInclude],ModelEmbedding)\n",
    "    Zmu = np.reshape(mu, (500, 500))\n",
    "    Zsigma = np.reshape(sigma, (500, 500))\n",
    "\n",
    "    conf0 = np.array(mu - 2 * sigma).reshape(500, 500)\n",
    "    conf1 = np.array(mu + 2 * sigma).reshape(500, 500)\n",
    "\n",
    "    X0p, X1p = np.meshgrid(x, y, indexing='ij')\n",
    "\n",
    "    ax = axs[count,0]\n",
    "\n",
    "    pcm = ax.pcolormesh(X0p, X1p, Zmu,vmax=vmax,vmin=vmin,cmap=cm[0],rasterized=True)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.set_xlim(-50, 50)\n",
    "    ax.set_ylim(-50, 50)\n",
    "    ax = axs[count,1]\n",
    "\n",
    "    pcm = ax.pcolormesh(X0p, X1p, Zsigma,cmap=cm[1],rasterized=True)#,vmax=vmax,vmin=vmin)    \n",
    "    ax.set_title(\"Iterations: %i\" % (NumSamplesToInclude),fontsize=15,fontweight=\"bold\")\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    ax.set_xlim(-50, 50)\n",
    "    ax.set_ylim(-50, 50)\n",
    "\n",
    "    ax = axs[count,2]\n",
    "    pcm=ax.scatter(muModEmb[PredictedAcc!=PredictedAcc.min()],PredictedAcc[PredictedAcc!=PredictedAcc.min()],marker='.',c='gray',rasterized=True)\n",
    "    ax.set_xlim(-0.225, -0.265)\n",
    "    ax.set_ylim(-0.225, -0.265)\n",
    "    ax.set_aspect('equal', 'box')\n",
    "\n",
    "    count=count+1\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig(str(output_path / 'BOptEvolutionK10.svg'),format='svg',dpi=300)\n",
    "\n",
    "\n",
    "#Calculate the correlation between the actual and predicted space\n",
    "\n",
    "print(np.corrcoef(muModEmb,PredictedAcc))\n",
    "print(spearmanr(muModEmb,PredictedAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMD8DNNKLxNu"
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "from helperfunctions import objectiveFunc, bayesian_optimisation, display_gp_mean_uncertainty\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RBF, ConstantKernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "kernel = 1.0 * Matern(length_scale=25, length_scale_bounds=(10,80),nu=2.5) \\\n",
    "    + WhiteKernel(noise_level=0.1, noise_level_bounds=(1e-10, 0.1))\n",
    "\n",
    "lb1 = np.min(ModelEmbedding[:, 0])\n",
    "hb1 = np.max(ModelEmbedding[:, 0])\n",
    "lb2 = np.min(ModelEmbedding[:, 1])\n",
    "hb2 = np.max(ModelEmbedding[:, 1])\n",
    "pbounds = {'b1': (lb1, hb1), 'b2': (lb2, hb2)}\n",
    "\n",
    "BestModelGPSpace=np.zeros(20)\n",
    "BestModelGPSpaceModIndex=np.zeros(20)\n",
    "BestModelEmpirical=np.zeros(20)\n",
    "BestModelEmpiricalModIndex=np.zeros(20)\n",
    "ModelActualAccuracyCorrelation=np.zeros(20)\n",
    "CVPValBestModels=np.zeros(20)\n",
    "\n",
    "for DiffInit in range(0,20):\n",
    "    optimizer = BayesianOptimization(f=None,\n",
    "                                     pbounds=pbounds,\n",
    "                                     verbose=4,\n",
    "                                     random_state=166+DiffInit)\n",
    "\n",
    "    optimizer.set_gp_params(kernel=kernel,normalize_y=True,n_restarts_optimizer=10)\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(ModelEmbedding)\n",
    "\n",
    "    distances, indices = nbrs.kneighbors(ModelEmbedding)\n",
    "\n",
    "    utility = UtilityFunction(kind=\"ucb\", kappa=10,xi=1e-1)\n",
    "\n",
    "\n",
    "    n_iter=10\n",
    "    init_points=10\n",
    "    RandomSeed=111+DiffInit\n",
    "    np.random.seed(RandomSeed)\n",
    "    FailedIters=bayesian_optimisation(kernel, optimizer, utility, init_points,\n",
    "                                      n_iter, pbounds, nbrs,RandomSeed,\n",
    "                                      ModelEmbedding,BCT_models,BCT_Run,\n",
    "                                      Sparsities_Run,Data_Run,AgesPrediction,\n",
    "                                      KeptYeoIDs,MainNoNanPrediction,\n",
    "                                      GSRNoNanPrediction,1,-1)\n",
    "    \n",
    "    gp = GaussianProcessRegressor(kernel=kernel, normalize_y=True,\n",
    "                                  n_restarts_optimizer=10)\n",
    "\n",
    "    x_temp = np.array([[res[\"params\"][\"b1\"]] for res in optimizer.res])\n",
    "    y_temp = np.array([[res[\"params\"][\"b2\"]] for res in optimizer.res])\n",
    "    z_temp = np.array([res[\"target\"] for res in optimizer.res])\n",
    "\n",
    "    x_obs=x_temp[FailedIters==0]\n",
    "    y_obs=y_temp[FailedIters==0]\n",
    "    z_obs=z_temp[FailedIters==0]\n",
    "    \n",
    "    muModEmb,sigmaModEmb,gpModEmb=posteriorOnlyModels(gp, x_obs, y_obs, z_obs,ModelEmbedding)\n",
    "    \n",
    "    BestModelGPSpace[DiffInit]=muModEmb.max()\n",
    "    BestModelGPSpaceModIndex[DiffInit]=muModEmb.argmax()\n",
    "    BestModelEmpirical[DiffInit]=z_obs.max()\n",
    "    Model_coord = np.array([[x_obs[z_obs.argmax()][-1], y_obs[z_obs.argmax()][-1]]])\n",
    "    BestModelEmpiricalModIndex[DiffInit]=nbrs.kneighbors(Model_coord)[1][0][0]\n",
    "    ModelActualAccuracyCorrelation[DiffInit]=spearmanr(muModEmb,PredictedAcc)[0]\n",
    "    \n",
    "    ClassOrRegress=1\n",
    "    TempModelNum=muModEmb.argmax()\n",
    "    Y=AgesPrediction\n",
    "    CommunityIDs=KeptYeoIDs\n",
    "    if Data_Run[TempModelNum]==0:\n",
    "        TempData=MainNoNanPrediction # BUG BUG BUG \n",
    "        TotalRegions=346\n",
    "        TotalSubjects=TempData.shape[2]\n",
    "    elif Data_Run[TempModelNum]==1:\n",
    "        TempData=GSRNoNanPrediction\n",
    "        TotalRegions=346\n",
    "        TotalSubjects=TempData.shape[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    TempThreshold=Sparsities_Run[TempModelNum]\n",
    "    \n",
    "    BCT_Num=[i for i, e in enumerate(BCT_models) if e[0] == BCT_Run[TempModelNum]][0]\n",
    "    \n",
    "    TempResults=np.zeros([TotalSubjects,TotalRegions])\n",
    "    for SubNum in range(0,TotalSubjects):\n",
    "        x = bct.threshold_proportional(TempData[:,:,SubNum], TempThreshold, copy=True)\n",
    "        if BCT_Num==7:\n",
    "            s=np.asarray(BCT_models[BCT_Num][1](x,1))\n",
    "        elif BCT_Num==8:\n",
    "            temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "            s=temp_s[0]\n",
    "        elif BCT_Num==9:\n",
    "            temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "            s=temp_s[0]\n",
    "        elif BCT_Num==10:\n",
    "            s=np.asarray(BCT_models[BCT_Num][1](x,CommunityIDs))\n",
    "        elif BCT_Num==11:\n",
    "            s=np.asarray(BCT_models[BCT_Num][1](x,CommunityIDs))\n",
    "        elif BCT_Num==12:\n",
    "            s=np.asarray(BCT_models[BCT_Num][1](x,0.85))\n",
    "                #elif BCT_Num==13:\n",
    "                #   temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "                #   s=temp_s[0]\n",
    "        elif BCT_Num==13:\n",
    "                #temp_s=np.asarray(BCT_models[BCT_Num][1](x,KeptYeoIDs,'degree'))\n",
    "            temp_s=np.asarray(BCT_models[BCT_Num][1](x,CommunityIDs))\n",
    "            s=temp_s[0] \n",
    "        elif BCT_Num==14:\n",
    "            temp_s=np.asarray(BCT_models[BCT_Num][1](x,CommunityIDs))\n",
    "            s=temp_s[0] \n",
    "        elif BCT_Num==15:\n",
    "            temp_s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "            s=temp_s[0]\n",
    "        else:\n",
    "            s=np.asarray(BCT_models[BCT_Num][1](x))\n",
    "\n",
    "        TempResults[SubNum,:]=s \n",
    "    scaler = StandardScaler()\n",
    "    TempResults=scaler.fit_transform(TempResults)\n",
    "  \n",
    "    model = SVR(C=1.0, epsilon=0.2)\n",
    "    rs = np.random.RandomState(100)\n",
    "    TempScore=permutation_test_score(model, TempResults, AgesPrediction.ravel(),\n",
    "                                     groups=None, cv=None, n_permutations=5000, \n",
    "                                     n_jobs=None, random_state=5, verbose=0,\n",
    "                                     scoring=\"neg_mean_absolute_error\")\n",
    "    CVPValBestModels[DiffInit]=TempScore[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_0lraz1fCt8"
   },
   "outputs": [],
   "source": [
    "#TEMP\n",
    "results = {}\n",
    "results['ModelEmbedding'] = ModelEmbedding\n",
    "results['BestModelGPSpaceModIndex'] = BestModelGPSpaceModIndex\n",
    "results['BestModelEmpiricalModIndex'] = BestModelEmpiricalModIndex\n",
    "results['BestModelEmpirical'] = BestModelEmpirical\n",
    "results['ModelActualAccuracyCorrelation'] = ModelActualAccuracyCorrelation\n",
    "results['TempResults'] = TempResults\n",
    "pickle.dump(results, open(str(output_path / 'results.pckl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMqeSsZlL28V"
   },
   "outputs": [],
   "source": [
    "# displaying results of 20 iterations\n",
    "\n",
    "fig8 = plt.figure(constrained_layout=False,figsize=(18,6))\n",
    "gs1 = fig8.add_gridspec(nrows=6, ncols=18)\n",
    "ax1 = fig8.add_subplot(gs1[:,0:6])\n",
    "ax1.set_title('Optima GP regression: 20 iterations',fontsize=15,fontweight=\"bold\")\n",
    "ax1.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],\n",
    "            ModelEmbedding[0:PredictedAcc.shape[0],1],\n",
    "            c=PredictedAcc,vmax=vmax,vmin=vmin,cmap='coolwarm',alpha=0.2,s=120)\n",
    "ax1.scatter(ModelEmbedding[BestModelGPSpaceModIndex.astype(int)][:,0],\n",
    "            ModelEmbedding[BestModelGPSpaceModIndex.astype(int)][:,1],s=120,c='black')\n",
    "\n",
    "ax1.set_xlim(-50, 50)\n",
    "ax1.set_ylim(-50, 50)\n",
    "\n",
    "ax2 = fig8.add_subplot(gs1[:,7:13])\n",
    "ax2.set_title('Empirical optima: 20 iterations',fontsize=15,fontweight=\"bold\")\n",
    "ax2.scatter(ModelEmbedding[0:PredictedAcc.shape[0],0],\n",
    "            ModelEmbedding[0:PredictedAcc.shape[0],1],\n",
    "            c=PredictedAcc,vmax=vmax,vmin=vmin,cmap='coolwarm',s=120,alpha=0.2)\n",
    "ax2.scatter(ModelEmbedding[BestModelEmpiricalModIndex.astype(int)][:,0],\n",
    "            ModelEmbedding[BestModelEmpiricalModIndex.astype(int)][:,1],c='black',s=120)\n",
    "\n",
    "ax2.set_xlim(-50, 50)\n",
    "ax2.set_ylim(-50, 50)\n",
    "\n",
    "ax3 = fig8.add_subplot(gs1[:,14:16])\n",
    "ax3.violinplot([PredictedAcc,BestModelEmpirical])\n",
    "ax3.set_xticks([1, 2])\n",
    "ax3.set_xticklabels(['Accuracy \\n of all points', 'Accuracy\\n of optima'],fontsize=9)\n",
    "\n",
    "ax4 = fig8.add_subplot(gs1[:,17:18])\n",
    "ax4.violinplot([ModelActualAccuracyCorrelation])\n",
    "ax4.set_xticks([1])\n",
    "ax4.set_xticklabels(['Correlation: \\n est vs emp '],fontsize=9)\n",
    "\n",
    "gs1\n",
    "fig8.savefig(str(output_path / 'BOpt20Repeats.png'),dpi=300) \n",
    "fig8.savefig(str(output_path / 'BOpt20Repeats.svg'),format=\"svg\") "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNqhKrgAeDovjzWoJPkIayP",
   "collapsed_sections": [],
   "name": "multiverse_test.ipynb",
   "provenance": [
    {
     "file_id": "1p4GrNQtqREI5xsS5Lc32KIU1ZLx-OnON",
     "timestamp": 1596017136874
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
